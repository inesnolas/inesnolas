<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Academic personal webpage">
    <title>Ines Nolasco - Academic Profile</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600&family=Nunito:wght@600;700;800&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <nav class="navbar">
        <div class="nav-container">
            <h1 class="nav-title">Ines Nolasco</h1>
            <ul class="nav-links">
                <li><a href="#about">About</a></li>
                <li><a href="#publications">Publications</a></li>
                <li><a href="cv.pdf" target="_blank">CV</a></li>
                <li><a href="#news">News & Tidbits</a></li>
            </ul>
        </div>
    </nav>

    <main class="container">
        <section id="about" class="section hero">
            <div class="hero-content">
                <div class="profile-image">
                    <img src="profile.jpg" alt="Profile photo" onerror="this.style.display='none'">
                    <p style="text-align: center; margin-top: 0.75rem; font-size: 0.9rem; color: var(--text-light);">üìç Based in London</p>
                </div>
                <div class="hero-text">
                    <p class="position">Postdoctoral Researcher<br>in Computational Bioacoustics and Animal Communication</p>
                    <p class="bio">
                        I am a Postdoctoral Researcher at <a href="https://www.earthspecies.org/" target="_blank" style="color: var(--secondary-color); text-decoration: none;">Earth Species Project</a>, working in computational bioacoustics and animal communication. My research focuses on developing machine learning methods to understand how animals communicate, with applications in conservation and biodiversity monitoring. 
                    </p>
                    <p class="bio">
                        I come from a computer science background and began working in bioacoustics by analysing beehive sounds to understand how the bee colony is doing. This work sparked my interest in applying machine learning more broadly to decode animal vocal communication across species. I received my Ph.D. from Queen Mary University of London in 2025, where my dissertation focused on acoustic identification of individual animals using deep learning approaches.
                    </p>
                    <p class="bio">
                        What drives my work is a desire to understand the behavior of other animals. By developing computational tools to study how different species communicate, I aim to expand our knowledge of their worlds and, in doing so, foster greater empathy and acceptance towards other forms of life.      </p>
                    <div class="hero-links">
                        <a href="cv.pdf" class="btn" target="_blank">View CV</a>
                        <a href="https://scholar.google.com/citations?hl=en&user=C1jftogAAAAJ&view_op=list_works&sortby=pubdate" class="btn btn-secondary">Google Scholar</a>
                    </div>
                </div>
            </div>

            <div class="current-work" style="margin-top: 3rem;">
                <div class="work-card">
                    <h3>üî¨ What I'm Working On</h3>
                    <ul class="work-list">
                        <li><strong>Embedding Analysis:</strong> Understanding what embeddings are encoding in bioacoustic signals</li>
                        <li><strong>BioDCASE:</strong> Organisation and coordination as task chair</li>
                    </ul>
                </div>

                <div class="status-card">
                    <h3>üí° Currently Learning/Exploring</h3>
                    <p><strong>Research:</strong> Explainable AI and interpretability methods</p>
                    <p style="margin-top: 0.75rem;"><strong>Reading:</strong> <em>The Ministry of Utmost Happiness</em> by Arundhati Roy, and <em>The Planetization of Machine Listening</em></p>
                </div>
            </div>
        </section>

        <section id="publications" class="section">
            <h2>Selected Publications</h2>

            <!-- PhD Thesis - Separated at top -->
            <article class="publication thesis-highlight">
                <h3>PhD Thesis: Acoustic identification of individual animals</h3>
                <p class="authors"><strong>In√™s Nolasco</strong></p>
                <p class="venue">Queen Mary University of London, 2025</p>
                <div class="pub-links">
                    <a href="thesis.pdf" target="_blank">PDF</a>
                </div>
            </article>

            <!-- All other publications grouped together -->
            <div class="publications-container">
                <article class="publication-item">
                    <h3>Acoustic identification of individual animals with hierarchical contrastive learning</h3>
                    <p class="authors"><strong>Ines Nolasco</strong>, Ilyass Moummad, Dan Stowell, Emmanouil Benetos</p>
                    <p class="venue"><em>ICASSP 2025 - IEEE International Conference on Acoustics, Speech and Signal Processing</em>, 2025</p>
                    <div class="pub-links">
                        <a href="https://arxiv.org/abs/2409.08673" target="_blank">arXiv</a>
                        <a href="https://doi.org/10.1109/ICASSP49660.2025.10890076" target="_blank">DOI</a>
                    </div>
                </article>

                <article class="publication-item">
                    <h3>Learning to detect an animal sound from five examples</h3>
                    <p class="authors"><strong>Ines Nolasco</strong>, et al.</p>
                    <p class="venue"><em>Ecological Informatics</em>, 77 (2023): 102258</p>
                    <div class="pub-links">
                        <a href="https://arxiv.org/abs/2305.13210" target="_blank">arXiv</a>
                        <a href="https://doi.org/10.1016/j.ecoinf.2023.102258" target="_blank">DOI</a>
                    </div>
                </article>

                <article class="publication-item">
                    <h3>Rank-based loss for learning hierarchical representations</h3>
                    <p class="authors"><strong>In√™s Nolasco</strong>, Dan Stowell</p>
                    <p class="venue"><em>ICASSP 2022 - IEEE International Conference on Acoustics, Speech and Signal Processing</em>, 2022</p>
                    <div class="pub-links">
                        <a href="https://arxiv.org/abs/2110.05941" target="_blank">arXiv</a>
                        <a href="https://doi.org/10.1109/ICASSP43922.2022.9746907" target="_blank">DOI</a>
                        <a href="https://github.com/inesnolas/Rank-based-loss_ICASSP22" target="_blank">Code</a>
                    </div>
                </article>

                <article class="publication-item">
                    <h3>Few-Shot Bioacoustic Event Detection: A New Task at the DCASE 2021 Challenge</h3>
                    <p class="authors">Veronica Morfi, <strong>In√™s Nolasco</strong>, et al.</p>
                    <p class="venue"><em>DCASE 2021</em>, 2021</p>
                    <div class="pub-links">
                        <a href="https://dcase.community/challenge2021/task-few-shot-bioacoustic-event-detection" target="_blank">DCASE</a>
                        <a href="https://github.com/c4dm/dcase-few-shot-bioacoustic" target="_blank">Code</a>
                    </div>
                </article>

                <article class="publication-item">
                    <h3>Audio-based identification of beehive states</h3>
                    <p class="authors"><strong>In√™s Nolasco</strong>, Alessandro Terenzi, Stefania Cecchi, Simone Orcioni</p>
                    <p class="venue"><em>ICASSP 2019 - IEEE International Conference on Acoustics, Speech and Signal Processing</em>, 2019</p>
                    <div class="pub-links">
                        <a href="https://arxiv.org/abs/1811.06330" target="_blank">arXiv</a>
                        <a href="https://doi.org/10.1109/ICASSP.2019.8682981" target="_blank">DOI</a>
                        <a href="https://zenodo.org/records/2667806" target="_blank">Dataset</a>
                        <a href="https://github.com/inesnolas/Audio_based_identification_beehive_states" target="_blank">Code</a>
                    </div>
                </article>

                <article class="publication-item">
                    <h3>To bee or not to bee: Investigating machine learning approaches for beehive sound recognition</h3>
                    <p class="authors"><strong>In√™s Nolasco</strong>, Emmanouil Benetos</p>
                    <p class="venue"><em>arXiv preprint</em> arXiv:1811.06016, 2018</p>
                    <div class="pub-links">
                        <a href="https://arxiv.org/abs/1811.06016" target="_blank">arXiv</a>
                        <a href="https://zenodo.org/records/1321278" target="_blank">Dataset</a>
                    </div>
                </article>
            </div>

            <a href="https://scholar.google.com/citations?hl=en&user=C1jftogAAAAJ&view_op=list_works&sortby=pubdate" class="view-all">View all publications on Google Scholar ‚Üí</a>
        </section>

        <section id="news" class="section">
            <h2>News & Tidbits</h2>
            <div class="news-wall">
                
                <div class="news-item">
                    <div class="news-date">February 2026</div>
                    <div class="news-content">
                        <h3>üì¢ New tasks at BioDCASE 2026</h3>
                        <p> BioDCASE 2026 will host 6 tasks! We were very happy to have received many great task proposals, which made the selection process quite challenging.
                            In addition to the 3 tasks that launched this challenge last year, this edition we will introduce new tasks focusing on mosquitoes, bird counting and active learning. 
                            Find more details on the <a href="https://biodcase.github.io/challenge2026/summary" >BioDCASE website</a></p>
                    </div>
                </div>
                 <div class="news-item">
                    <div class="news-date">January 2026</div>
                    <div class="news-content">
                        <h3> A Robin sang us a song</h3>
                        <img src="biodcase-image.jpg" alt="A Robin" style="width: 100%; max-width: 300px; border-radius: 8px; margin: 1rem 0;">
                        <p> after reading so many times about playback experiments, I finally had the chance of trying it myself... This cute fellow seemed very eager to respond to my youtube clips of robins singing. </p>
                    </div>
                </div>
                <div class="news-item">
                    <div class="news-date">December 2025</div>
                    <div class="news-content">
                        <h3>üì¢ Call for Task Proposals</h3>
                        <p>BioDCASE is now accepting task proposals for the upcoming challenge. If you're working on bioacoustic research and have interesting datasets or problems to share with the community, please consider submitting a proposal!</p>
                    </div>
                </div>

                <div class="news-item">
                    <div class="news-date">October 2025</div>
                    <div class="news-content">
                        <h3>üéâ New Position at Earth Species Project</h3>
                        <p>I'm very happy to say that I started as a postdoc researcher at Earth Species Project! I'll be continuing working on the intersection of computer science and bioacoustics, this time towards the decoding of animal communication.</p>
                    </div>
                </div>
            </div>
        </section>

        <section id="contact" class="section">
            <h2>Get In Touch</h2>
            <div class="contact-info">
                <div class="contact-item">
                    <strong>Email:</strong><br>
                    <a href="mailto:ines@earthspecies.org">ines@earthspecies.org</a><br>
                    <a href="mailto:a.nolasco.ines@gmail.com">a.nolasco.ines@gmail.com</a>
                </div>
                <div class="social-links">
                    <a href="https://scholar.google.com/citations?hl=en&user=C1jftogAAAAJ&view_op=list_works&sortby=pubdate" aria-label="Google Scholar">
                        <svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor">
                            <path d="M12 24a7 7 0 1 1 0-14 7 7 0 0 1 0 14zm0-24L0 9.5l4.838 3.94A8 8 0 0 1 12 9a8 8 0 0 1 7.162 4.44L24 9.5z"/>
                        </svg>
                    </a>
                    <a href="https://github.com/inesnolas" aria-label="GitHub">
                        <svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor">
                            <path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/>
                        </svg>
                    </a>
                    <a href="https://bsky.app/profile/inesnolas.bsky.social" aria-label="Bluesky">
                        <svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor">
                            <path d="M12 10.8c-1.087-2.114-4.046-6.053-6.798-7.995C2.566.944 1.561 1.266.902 1.565.139 1.908 0 3.08 0 3.768c0 .69.378 5.65.624 6.479.815 2.736 3.713 3.66 6.383 3.364.136-.02.275-.038.415-.056-.138.022-.276.04-.415.056-3.912.58-7.387 2.005-2.83 7.078 5.013 5.19 6.87-1.113 7.823-4.308.953 3.195 2.05 9.271 7.733 4.308 4.267-4.308 1.172-6.498-2.74-7.078a8.741 8.741 0 0 1-.415-.056c.14.018.279.036.415.056 2.67.297 5.568-.628 6.383-3.364.246-.828.624-5.79.624-6.478 0-.69-.139-1.861-.902-2.206-.659-.298-1.664-.62-4.3 1.24C16.046 4.748 13.087 8.687 12 10.8Z"/>
                        </svg>
                    </a>
                    <a href="https://www.linkedin.com/in/ines-nolasco/" aria-label="LinkedIn">
                        <svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor">
                            <path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"/>
                        </svg>
                    </a>
                </div>
            </div>
        </section>
    </main>

    <footer class="footer">
        <p>&copy; 2026 Ines Nolasco. Last updated: <span id="last-updated"></span></p>
    </footer>

    <script>
        // Smooth scrolling for navigation links
        document.querySelectorAll('a[href^="#"]').forEach(anchor => {
            anchor.addEventListener('click', function (e) {
                e.preventDefault();
                const target = document.querySelector(this.getAttribute('href'));
                if (target) {
                    target.scrollIntoView({ behavior: 'smooth', block: 'start' });
                }
            });
        });

        // Display last updated date
        document.getElementById('last-updated').textContent = new Date().toLocaleDateString('en-US', {
            year: 'numeric',
            month: 'long',
            day: 'numeric'
        });

        // Mobile menu toggle
        const createMobileMenu = () => {
            const navToggle = document.createElement('button');
            navToggle.className = 'nav-toggle';
            navToggle.innerHTML = '‚ò∞';
            navToggle.setAttribute('aria-label', 'Toggle navigation');

            const navContainer = document.querySelector('.nav-container');
            const navLinks = document.querySelector('.nav-links');

            if (window.innerWidth <= 768) {
                navContainer.prepend(navToggle);

                navToggle.addEventListener('click', () => {
                    navLinks.classList.toggle('active');
                });
            }
        };

        if (window.innerWidth <= 768) {
            createMobileMenu();
        }

    </script>
</body>
</html>
